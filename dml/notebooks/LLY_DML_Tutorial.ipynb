{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLY-DML: Quantum Circuit Training mit L-Gates\n",
    "\n",
    "<div style=\"text-align: center; padding: 10px; margin: 10px;\">\n",
    "    <h3>LILY Quantum Machine Learning - Differentiable Machine Learning</h3>\n",
    "    <p style=\"font-style: italic;\">Ein Tutorial zur Quantenoptimierung mit L-Gates</p>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation der benötigten Pakete\n",
    "\n",
    "Da wir dieses Notebook in Google Colab ausführen, installieren wir zunächst alle notwendigen Pakete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation der benötigten Bibliotheken\n",
    "!pip install qiskit matplotlib numpy seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einführung zu L-Gates\n",
    "\n",
    "Die L-Gate-Struktur ist das Grundelement unserer quantum-basierten Lernarchitektur. Ein L-Gate besteht aus einer spezifischen Abfolge von Quantengates:\n",
    "\n",
    "```\n",
    "TP0 → IP0 → H → TP1 → IP1 → H → TP2 → IP2\n",
    "```\n",
    "\n",
    "Wobei:\n",
    "- **TP** = Trainingsphase (P-Gate mit trainierbare Parameter)\n",
    "- **IP** = Inputphase (P-Gate mit feste Inputparameter)\n",
    "- **H** = Hadamard-Gate (festes Gate ohne Parameter)\n",
    "\n",
    "Diese Struktur wird für jeden Qubit und in der festgelegten Tiefe (Depth) wiederholt. Die L-Gate-Struktur ermöglicht es uns, einen Quantum Circuit zu trainieren, sodass er verschiedene Eingaben (Inputmatrizen) auf unterschiedliche Quantenzustände abbildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basisbibliotheken importieren\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Qiskit für Quantum Circuit Simulation\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.visualization import circuit_drawer\n",
    "\n",
    "# Logging konfigurieren\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"DML-Tutorial\")\n",
    "\n",
    "# Matplotlib-Stil setzen\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisierung eines L-Gates\n",
    "\n",
    "Lass uns ein einzelnes L-Gate visualisieren, um seine Struktur besser zu verstehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle einen einfachen L-Gate-Circuit für die Visualisierung\n",
    "l_gate_circuit = QuantumCircuit(1)\n",
    "\n",
    "# Füge ein L-Gate hinzu\n",
    "# TP0 → IP0 → H → TP1 → IP1 → H → TP2 → IP2\n",
    "l_gate_circuit.p(0.1, 0)  # TP0 - Trainingsphase 0 (trainierbar)\n",
    "l_gate_circuit.p(0.2, 0)  # IP0 - Inputphase 0 (fest)\n",
    "l_gate_circuit.h(0)       # H   - Hadamard-Gate\n",
    "l_gate_circuit.p(0.3, 0)  # TP1 - Trainingsphase 1 (trainierbar)\n",
    "l_gate_circuit.p(0.4, 0)  # IP1 - Inputphase 1 (fest)\n",
    "l_gate_circuit.h(0)       # H   - Hadamard-Gate\n",
    "l_gate_circuit.p(0.5, 0)  # TP2 - Trainingsphase 2 (trainierbar)\n",
    "l_gate_circuit.p(0.6, 0)  # IP2 - Inputphase 2 (fest)\n",
    "\n",
    "# Visualisiere den L-Gate-Circuit\n",
    "plt.figure(figsize=(16, 4))\n",
    "circuit_drawer(l_gate_circuit, output='mpl', style={\"name\": \"bw\", \"cregbundle\": False})\n",
    "plt.title(\"Struktur eines einzelnen L-Gates\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Erläuterung des L-Gates\n",
    "print(\"L-Gate-Struktur besteht aus 8 Gates in dieser Reihenfolge:\")\n",
    "print(\"1. TP0 (P-Gate): Trainingsphase 0 - trainierbar\")\n",
    "print(\"2. IP0 (P-Gate): Inputphase 0 - fester Input\")\n",
    "print(\"3. H (Hadamard): Superposition erzeugen\")\n",
    "print(\"4. TP1 (P-Gate): Trainingsphase 1 - trainierbar\")\n",
    "print(\"5. IP1 (P-Gate): Inputphase 1 - fester Input\")\n",
    "print(\"6. H (Hadamard): Superposition erzeugen\")\n",
    "print(\"7. TP2 (P-Gate): Trainingsphase 2 - trainierbar\")\n",
    "print(\"8. IP2 (P-Gate): Inputphase 2 - fester Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementierung des LLY-DML Circuit-Systems\n",
    "\n",
    "Da wir in Google Colab arbeiten und keinen direkten Zugriff auf das LLY-DML-Framework haben, implementieren wir hier eine vereinfachte Version der Circuit- und Optimizer-Klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementierung des Circuit-Systems\n",
    "class Circuit:\n",
    "    \"\"\"\n",
    "    Vereinfachte Implementierung der LLY-DML Circuit-Klasse für dieses Tutorial.\n",
    "    \"\"\"\n",
    "    def __init__(self, qubits, depth, training_phases=None, activation_phases=None, shots=1024):\n",
    "        \"\"\"\n",
    "        Initialisiert einen Quantum Circuit mit angegebener Qubit-Anzahl und Tiefe.\n",
    "        \n",
    "        Args:\n",
    "            qubits (int): Anzahl der Qubits im Circuit\n",
    "            depth (int): Anzahl der L-Gates pro Qubit\n",
    "            training_phases (list, optional): 3D-Matrix mit Trainingsparametern [qubits × depth × 3]\n",
    "            activation_phases (list, optional): 3D-Matrix mit Aktivierungsparametern [qubits × depth × 3]\n",
    "            shots (int, optional): Anzahl der Messungen bei der Ausführung\n",
    "        \"\"\"\n",
    "        self.qubits = qubits\n",
    "        self.depth = depth\n",
    "        self.shots = shots\n",
    "        self.simulation_result = None\n",
    "        \n",
    "        # Erstelle die Circuit-Struktur\n",
    "        self.circuit = None\n",
    "        self.build_circuit()\n",
    "        \n",
    "        # Initialisiere Trainings- und Aktivierungsmatrizen wenn nicht angegeben\n",
    "        if training_phases is None:\n",
    "            self.training_phases = self.create_matrix()\n",
    "        else:\n",
    "            self.training_phases = training_phases\n",
    "            \n",
    "        if activation_phases is None:\n",
    "            self.activation_phases = self.create_matrix()\n",
    "        else:\n",
    "            self.activation_phases = activation_phases\n",
    "            \n",
    "        # Platziere Gates im Circuit\n",
    "        self.place_matrices()\n",
    "    \n",
    "    def build_circuit(self):\n",
    "        \"\"\"\n",
    "        Erstellt einen leeren Quantum Circuit mit der angegebenen Anzahl von Qubits.\n",
    "        \"\"\"\n",
    "        from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "        q_register = QuantumRegister(self.qubits, 'q')\n",
    "        c_register = ClassicalRegister(self.qubits, 'c')\n",
    "        self.circuit = QuantumCircuit(q_register, c_register)\n",
    "    \n",
    "    def create_matrix(self):\n",
    "        \"\"\"\n",
    "        Erstellt eine Matrix mit zufälligen Werten zwischen 0 und 2π.\n",
    "        \n",
    "        Returns:\n",
    "            list: 3D-Matrix mit zufälligen Werten [qubits × depth × 3]\n",
    "        \"\"\"\n",
    "        matrix = np.random.random((self.qubits, self.depth, 3)) * 2 * np.pi\n",
    "        return matrix.tolist()\n",
    "    \n",
    "    def place_matrices(self):\n",
    "        \"\"\"\n",
    "        Überträgt die Trainings- und Aktivierungsdaten aus den Matrizen in den Quantum Circuit.\n",
    "        \"\"\"\n",
    "        # Validiere die Dimensionen der Matrizen\n",
    "        if len(self.training_phases) != self.qubits or len(self.activation_phases) != self.qubits:\n",
    "            raise ValueError(f\"Training and activation phases must each have {self.qubits} rows.\")\n",
    "            \n",
    "        # Platziere L-Gates für jedes Qubit\n",
    "        for qubit in range(self.qubits):\n",
    "            for d in range(self.depth):\n",
    "                # Ein L-Gate besteht aus 3 Phasen mit jeweils Trainings- und Aktivierungsphase\n",
    "                for phase in range(3):\n",
    "                    # Index in der Trainings-/Aktivierungsmatrix\n",
    "                    phase_index = phase\n",
    "                    \n",
    "                    # Trainingsphase mit Phasengates (p)\n",
    "                    self.circuit.p(self.training_phases[qubit][d][phase_index], qubit)\n",
    "                    self.circuit.p(self.activation_phases[qubit][d][phase_index], qubit)\n",
    "                    \n",
    "                    # Hadamard nach Phase 0 und 1\n",
    "                    if phase == 0 or phase == 1:\n",
    "                        self.circuit.h(qubit)\n",
    "    \n",
    "    def place_measurement(self):\n",
    "        \"\"\"\n",
    "        Fügt Messgates für alle Qubits am Ende des Circuits hinzu.\n",
    "        \"\"\"\n",
    "        self.circuit.measure(range(self.qubits), range(self.qubits))\n",
    "    \n",
    "    def plot_circuit(self):\n",
    "        \"\"\"\n",
    "        Zeichnet den aktuellen Quantum Circuit.\n",
    "        \"\"\"\n",
    "        from qiskit.visualization import circuit_drawer\n",
    "        return circuit_drawer(self.circuit, output='mpl', style={'name': 'bw'})\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Führt den Quantum Circuit auf dem Simulator aus.\n",
    "        \"\"\"\n",
    "        from qiskit import Aer, transpile\n",
    "        \n",
    "        # Füge Messungen hinzu, falls noch nicht vorhanden\n",
    "        if not hasattr(self.circuit, 'cregs') or not self.circuit.cregs:\n",
    "            self.place_measurement()\n",
    "            \n",
    "        simulator = Aer.get_backend('aer_simulator')\n",
    "        compiled_circuit = transpile(self.circuit, simulator)\n",
    "        self.simulation_result = simulator.run(compiled_circuit, shots=self.shots).result()\n",
    "        return self.simulation_result\n",
    "    \n",
    "    def get_counts(self):\n",
    "        \"\"\"\n",
    "        Gibt die Messungsergebnisse als Dictionary zurück.\n",
    "        \"\"\"\n",
    "        if self.simulation_result is None:\n",
    "            raise RuntimeError(\"The circuit has not been executed yet.\")\n",
    "        return self.simulation_result.get_counts(self.circuit)\n",
    "    \n",
    "    def get_state_probabilities(self, counts=None):\n",
    "        \"\"\"\n",
    "        Berechnet die Wahrscheinlichkeiten der gemessenen Zustände.\n",
    "        \"\"\"\n",
    "        if counts is None:\n",
    "            if self.simulation_result is None:\n",
    "                raise RuntimeError(\"The circuit has not been executed yet.\")\n",
    "            counts = self.get_counts()\n",
    "            \n",
    "        total_shots = sum(counts.values())\n",
    "        return {state: count/total_shots for state, count in counts.items()}\n",
    "    \n",
    "    def set_train_parameters(self, parameters):\n",
    "        \"\"\"\n",
    "        Setzt die Trainingsparameter.\n",
    "        \"\"\"\n",
    "        if isinstance(parameters, np.ndarray):\n",
    "            self.training_phases = parameters.tolist()\n",
    "        else:\n",
    "            self.training_phases = parameters\n",
    "        return self.training_phases\n",
    "    \n",
    "    def place_train_matrix(self):\n",
    "        \"\"\"\n",
    "        Aktualisiert den Circuit mit den aktuellen Trainingsparametern.\n",
    "        \"\"\"\n",
    "        # Erstelle einen neuen Circuit\n",
    "        self.build_circuit()\n",
    "        # Platziere die Matrizen\n",
    "        self.place_matrices()\n",
    "        return self.circuit\n",
    "    \n",
    "    def place_input_parameters(self, input_data_matrix):\n",
    "        \"\"\"\n",
    "        Setzt die Inputparameter und aktualisiert den Circuit.\n",
    "        \"\"\"\n",
    "        if isinstance(input_data_matrix, np.ndarray):\n",
    "            self.activation_phases = input_data_matrix.tolist()\n",
    "        else:\n",
    "            self.activation_phases = input_data_matrix\n",
    "            \n",
    "        # Aktualisiere den Circuit\n",
    "        self.build_circuit()\n",
    "        self.place_matrices()\n",
    "        return self.circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementierung des Adam-Optimizers\n",
    "class AdamOptimizer:\n",
    "    \"\"\"\n",
    "    Vereinfachte Implementierung des Adam-Optimizers für dieses Tutorial.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, training_matrix, target_state, learning_rate=0.001, max_iterations=100, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.data = data\n",
    "        self.training_matrix = training_matrix\n",
    "        self.target_state = target_state\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # Initialisiere tuning_parameters mit der Trainingsmatrix\n",
    "        self.tuning_parameters = np.array(training_matrix)\n",
    "        # Initialisiere die Momentschätzer\n",
    "        self.m = np.zeros_like(self.tuning_parameters)\n",
    "        self.v = np.zeros_like(self.tuning_parameters)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Bewertet die aktuelle Matrix im Vergleich zum Zielzustand.\n",
    "        \"\"\"\n",
    "        return self.calculate_loss()\n",
    "    \n",
    "    def calculate_loss(self):\n",
    "        \"\"\"\n",
    "        Berechnet den Verlust basierend auf der Trainingsmatrix und dem Zielzustand.\n",
    "        \"\"\"\n",
    "        # Verlustfunktion basierend auf dem Zielzustand (ein einzelnes Bit '0' oder '1')\n",
    "        loss = 0\n",
    "        matrix_flat = self.tuning_parameters.flatten()\n",
    "        \n",
    "        # Das Zielbit als Integer konvertieren (0 oder 1)\n",
    "        desired_bit = int(self.target_state)\n",
    "        \n",
    "        # Für jeden Parameter in der flachen Matrix\n",
    "        for param in matrix_flat:\n",
    "            # Normalisiere den Parameter auf [0, 1]\n",
    "            normalized_param = (np.sin(param) + 1) / 2\n",
    "            \n",
    "            # Abstand zum gewünschten Bit berechnen\n",
    "            if desired_bit == 0:\n",
    "                loss += normalized_param  # Wenn 0 gewünscht, sollte der Parameter klein sein\n",
    "            else:\n",
    "                loss += (1 - normalized_param)  # Wenn 1 gewünscht, sollte der Parameter groß sein\n",
    "        \n",
    "        # Der durchschnittliche Verlust über alle Parameter\n",
    "        loss = loss / len(matrix_flat) if len(matrix_flat) > 0 else 0\n",
    "        return loss\n",
    "    \n",
    "    def calculate_loss_specific(self, params):\n",
    "        \"\"\"\n",
    "        Berechnet den Verlust für spezifische Parameter.\n",
    "        \"\"\"\n",
    "        # Ähnliche Implementierung wie calculate_loss, aber mit übergebenen Parametern\n",
    "        loss = 0\n",
    "        desired_bit = int(self.target_state)\n",
    "        \n",
    "        for param in params:\n",
    "            normalized_param = (np.sin(param) + 1) / 2\n",
    "            \n",
    "            if desired_bit == 0:\n",
    "                loss += normalized_param\n",
    "            else:\n",
    "                loss += (1 - normalized_param)\n",
    "        \n",
    "        loss = loss / len(params) if len(params) > 0 else 0\n",
    "        return loss\n",
    "    \n",
    "    def compute_gradient(self):\n",
    "        \"\"\"\n",
    "        Berechnet den Gradienten der Verlustfunktion nach den Trainingsparametern.\n",
    "        \"\"\"\n",
    "        params = self.tuning_parameters.flatten()\n",
    "        gradients = np.zeros_like(params)\n",
    "        \n",
    "        epsilon = 1e-5  # Kleine Änderung zur Berechnung der numerischen Ableitung\n",
    "        \n",
    "        for i in range(len(params)):\n",
    "            # Temporäre Parameter, um den Einfluss von Parameter i zu bewerten\n",
    "            params_plus = params.copy()\n",
    "            params_plus[i] += epsilon\n",
    "            \n",
    "            params_minus = params.copy()\n",
    "            params_minus[i] -= epsilon\n",
    "            \n",
    "            # Berechne den Gradienten mittels zentraler Differenz\n",
    "            loss_plus = self.calculate_loss_specific(params_plus)\n",
    "            loss_minus = self.calculate_loss_specific(params_minus)\n",
    "            \n",
    "            gradients[i] = (loss_plus - loss_minus) / (2 * epsilon)\n",
    "        \n",
    "        return gradients.reshape(self.tuning_parameters.shape)\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Führt den Adam-Optimierungsprozess durch.\n",
    "        \"\"\"\n",
    "        logging.info(\"AdamOptimizer: Startet den Optimierungsprozess\")\n",
    "        optimization_steps = []\n",
    "        \n",
    "        for iteration in range(1, self.max_iterations + 1):\n",
    "            # Berechne den aktuellen Verlust\n",
    "            loss = self.evaluate()\n",
    "            optimization_steps.append({\"iteration\": iteration, \"loss\": loss})\n",
    "            \n",
    "            # Frühzeitiger Abbruch bei minimalem Verlust\n",
    "            if loss == 0:\n",
    "                logging.info(\"AdamOptimizer: Verlust unter dem Schwellenwert, Optimierung abgeschlossen\")\n",
    "                break\n",
    "            \n",
    "            # Berechne den Gradienten\n",
    "            gradient = self.compute_gradient()\n",
    "            \n",
    "            # Adam-Optimierungsschritt\n",
    "            self.m = self.beta1 * self.m + (1 - self.beta1) * gradient\n",
    "            self.v = self.beta2 * self.v + (1 - self.beta2) * (gradient ** 2)\n",
    "            \n",
    "            # Bias-Korrektur\n",
    "            m_hat = self.m / (1 - self.beta1 ** iteration)\n",
    "            v_hat = self.v / (1 - self.beta2 ** iteration)\n",
    "            \n",
    "            # Update der Parameter\n",
    "            update = self.learning_rate * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "            self.tuning_parameters -= update\n",
    "        \n",
    "        logging.info(\"AdamOptimizer: Optimierungsprozess abgeschlossen\")\n",
    "        return self.tuning_parameters.tolist(), optimization_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ein einfaches Beispiel: Einzelne Eingabematrix und Circuit-Ausführung\n",
    "\n",
    "Bevor wir mit der Multi-Matrix-Optimierung beginnen, untersuchen wir, wie eine einzelne Eingabematrix in den Circuit eingesetzt wird und wie der Circuit aussieht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für den Beispiel-Circuit\n",
    "qubits = 5\n",
    "depth = 3\n",
    "shots = 1024\n",
    "\n",
    "# Erstelle eine Eingabematrix\n",
    "input_matrix = np.random.uniform(0, 2*np.pi, (qubits, depth, 3))\n",
    "print(f\"Eingabematrix-Form: {input_matrix.shape}\")\n",
    "\n",
    "# Visualisiere die Eingabematrix als Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "input_flat = input_matrix.reshape(qubits, -1)\n",
    "sns.heatmap(input_flat, cmap=\"viridis\", vmin=0, vmax=2*np.pi)\n",
    "plt.title(\"Beispiel-Eingabematrix - Werte zwischen 0 und 2π\")\n",
    "plt.xlabel(\"Parameter (flach: Tiefe × 3 Phasen)\")\n",
    "plt.ylabel(\"Qubit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Erstelle die Trainingsmatrix\n",
    "training_matrix = np.zeros((qubits, depth, 3))\n",
    "print(f\"Trainingsmatrix-Form: {training_matrix.shape}\")\n",
    "\n",
    "# Erstelle einen Circuit und setze die Matrix ein\n",
    "circuit = Circuit(qubits=qubits, depth=depth, \n",
    "                 training_phases=training_matrix.tolist(),\n",
    "                 activation_phases=input_matrix.tolist(),\n",
    "                 shots=shots)\n",
    "\n",
    "# Visualisiere den Circuit (begrenzt auf 2 Qubits und 1 L-Gate für die Übersichtlichkeit)\n",
    "smaller_circuit = Circuit(qubits=2, depth=1,\n",
    "                         training_phases=training_matrix[:2, :1, :].tolist(),\n",
    "                         activation_phases=input_matrix[:2, :1, :].tolist())\n",
    "smaller_circuit.place_measurement()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "smaller_circuit.plot_circuit()\n",
    "plt.title(\"Vereinfachter Circuit mit L-Gates (2 Qubits, 1 L-Gate)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Beschreibung der Matrixeinbettung\n",
    "print(\"Einbettung der Matrizen in den Circuit:\")\n",
    "print(\"1. Jedes Qubit bekommt eine Zeile aus der Matrix\")\n",
    "print(\"2. Jedes L-Gate verwendet 3 Werte aus jeder Matrix (Training und Input)\")\n",
    "print(\"3. Die Trainingsmatrix liefert die TP-Phasen (trainierbar)\")\n",
    "print(\"4. Die Eingabematrix liefert die IP-Phasen (fest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Matrix-Klassifikation: Training und Optimierung\n",
    "\n",
    "Jetzt kommen wir zum Hauptteil: Der Optimierung eines Circuits, um verschiedene Eingabematrizen auf unterschiedliche Zielzustände abzubilden. Dies entspricht einer Klassifikationsaufgabe in der Quantenwelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für die Multi-Matrix-Optimierung\n",
    "qubits = 5\n",
    "depth = 3\n",
    "shots = 1024\n",
    "num_matrices = 4  # Anzahl der Eingabematrizen\n",
    "\n",
    "# Erstelle mehrere Eingabematrizen\n",
    "input_matrices = []\n",
    "matrix_names = []\n",
    "\n",
    "for i in range(num_matrices):\n",
    "    # Verwende unterschiedliche Bereiche für verschiedene Matrizen\n",
    "    matrix = np.random.uniform(i*0.5, i*0.5 + 2*np.pi, (qubits, depth, 3))\n",
    "    input_matrices.append(matrix)\n",
    "    matrix_names.append(f\"Matrix_{i+1}\")\n",
    "\n",
    "# Definiere Zielzustände für jede Matrix\n",
    "target_states = {}\n",
    "for i, name in enumerate(matrix_names):\n",
    "    # Erzeuge einen binären Zustand mit der richtigen Länge\n",
    "    binary = format(i+1, f'0{qubits}b')\n",
    "    # Sichere die richtige Länge (gleich qubits)\n",
    "    target_states[name] = binary[-qubits:]\n",
    "\n",
    "# Zeige die zugewiesenen Zielzustände\n",
    "print(\"Zugewiesene Zielzustände für jede Matrix:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Matrix':10s} | {'Zielzustand':12s}\")\n",
    "print(\"-\" * 50)\n",
    "for name, state in target_states.items():\n",
    "    print(f\"{name:10s} | {state:12s}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiale Messungen\n",
    "\n",
    "Bevor wir mit der Optimierung beginnen, messen wir die anfänglichen Wahrscheinlichkeiten für jede Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere die gemeinsame Trainingsmatrix (zunächst alle Parameter 0)\n",
    "training_matrix = np.zeros((qubits, depth, 3))\n",
    "\n",
    "# Initiale Messungen für jede Matrix\n",
    "initial_measurements = []\n",
    "\n",
    "for i, (matrix, name) in enumerate(zip(input_matrices, matrix_names)):\n",
    "    target_state = target_states[name]\n",
    "    \n",
    "    # Erstelle einen Circuit mit der Trainings- und Eingabematrix\n",
    "    circuit = Circuit(qubits, depth, \n",
    "                      training_phases=training_matrix.tolist(),\n",
    "                      activation_phases=matrix.tolist())\n",
    "    \n",
    "    # Füge Messungen hinzu und führe den Circuit aus\n",
    "    circuit.place_measurement()\n",
    "    circuit.run()\n",
    "    counts = circuit.get_counts()\n",
    "    \n",
    "    # Berechne die Wahrscheinlichkeiten\n",
    "    probabilities = circuit.get_state_probabilities(counts)\n",
    "    \n",
    "    # Bestimme den wahrscheinlichsten Zustand\n",
    "    sorted_states = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    most_probable_state = sorted_states[0][0] if sorted_states else \"N/A\"\n",
    "    most_probable_prob = sorted_states[0][1] if sorted_states else 0\n",
    "    \n",
    "    # Berechne die Wahrscheinlichkeit des Zielzustands\n",
    "    target_probability = probabilities.get(target_state, 0)\n",
    "    \n",
    "    # Speichere die Messung\n",
    "    initial_measurements.append({\n",
    "        \"matrix_name\": name,\n",
    "        \"target_state\": target_state,\n",
    "        \"most_probable_state\": most_probable_state,\n",
    "        \"most_probable_prob\": most_probable_prob,\n",
    "        \"target_probability\": target_probability\n",
    "    })\n",
    "\n",
    "# Zeige die initialen Messungen\n",
    "print(\"Initiale Messungen vor der Optimierung:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Matrix':10s} | {'Zielzustand':12s} | {'Wahrscheinlichster':15s} | {'Wahrsch.':8s} | {'Ziel-Wahrsch.':12s}\")\n",
    "print(\"-\" * 80)\n",
    "for result in initial_measurements:\n",
    "    print(f\"{result['matrix_name']:10s} | {result['target_state']:12s} | \"\n",
    "          f\"{result['most_probable_state']:15s} | {result['most_probable_prob']:.4f} | \"\n",
    "          f\"{result['target_probability']:.4f}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierungsfunktion\n",
    "\n",
    "Implementieren wir eine Funktion, die die Trainingsmatrix für einen bestimmten Zielzustand optimiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_for_target_state(input_matrix, training_matrix, target_state, iterations=20):\n",
    "    \"\"\"\n",
    "    Optimiert eine Trainingsmatrix für eine Eingabematrix und einen Zielzustand.\n",
    "    \n",
    "    Args:\n",
    "        input_matrix: Die Eingabematrix für den Circuit\n",
    "        training_matrix: Die initiale Trainingsmatrix\n",
    "        target_state: Der Zielzustand als binärer String\n",
    "        iterations: Anzahl der Trainingsiterationen\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (optimierte Trainingsmatrix, Trainingsgeschichte)\n",
    "    \"\"\"\n",
    "    # Optimizer-Konfiguration\n",
    "    optimizer_data = {\"qubits\": qubits, \"depth\": depth}\n",
    "    \n",
    "    # Verwende das erste Bit des Zielzustands für den Optimizer\n",
    "    # (Vereinfachung für das Tutorial)\n",
    "    first_bit = target_state[0]\n",
    "    \n",
    "    # Adam-Optimizer initialisieren\n",
    "    optimizer = AdamOptimizer(\n",
    "        data=optimizer_data,\n",
    "        training_matrix=training_matrix.flatten().tolist(),\n",
    "        target_state=first_bit,\n",
    "        learning_rate=0.01,\n",
    "        max_iterations=iterations\n",
    "    )\n",
    "    \n",
    "    # Trainingsgeschichte initialisieren\n",
    "    history = []\n",
    "    current_matrix = training_matrix.copy()\n",
    "    \n",
    "    # Circuit für die Optimierung\n",
    "    circuit = Circuit(qubits, depth)\n",
    "    \n",
    "    # Training über mehrere Iterationen\n",
    "    for iteration in range(iterations):\n",
    "        # Aktualisiere den Circuit mit den aktuellen Matrizen\n",
    "        circuit.place_input_parameters(input_matrix)\n",
    "        circuit.set_train_parameters(current_matrix)\n",
    "        circuit.place_train_matrix()\n",
    "        \n",
    "        # Messung hinzufügen und Circuit ausführen\n",
    "        circuit.place_measurement()\n",
    "        circuit.run()\n",
    "        counts = circuit.get_counts()\n",
    "        \n",
    "        # Optimierungsschritt durchführen\n",
    "        try:\n",
    "            optimized_params, opt_steps = optimizer.optimize()\n",
    "            \n",
    "            # Reshape der optimierten Parameter\n",
    "            if len(optimized_params) == qubits * depth * 3:\n",
    "                reshaped_params = np.array(optimized_params).reshape(qubits, depth, 3)\n",
    "                current_matrix = reshaped_params\n",
    "            else:\n",
    "                logger.warning(f\"Optimierte Parameter haben falsche Größe: {len(optimized_params)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler bei der Optimierung: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Wahrscheinlichkeit des Zielzustands berechnen\n",
    "        probabilities = circuit.get_state_probabilities(counts)\n",
    "        target_prob = probabilities.get(target_state, 0.0)\n",
    "        \n",
    "        # Verlust aus dem letzten Optimierungsschritt\n",
    "        loss = opt_steps[-1][\"loss\"] if opt_steps else 1.0\n",
    "        \n",
    "        # Trainingsschritt speichern\n",
    "        history.append({\n",
    "            \"iteration\": iteration + 1,\n",
    "            \"target_probability\": target_prob,\n",
    "            \"loss\": loss\n",
    "        })\n",
    "        \n",
    "        # Status ausgeben\n",
    "        if (iteration + 1) % 5 == 0 or iteration == 0:\n",
    "            logger.info(f\"Iteration {iteration+1}/{iterations}, \"\n",
    "                        f\"Zielwahrscheinlichkeit: {target_prob:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return current_matrix, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durchführung der Optimierung\n",
    "\n",
    "Jetzt führen wir die Optimierung für alle Eingabematrizen sequentiell durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimierungsparameter\n",
    "training_iterations = 20\n",
    "\n",
    "# Ergebnisse speichern\n",
    "optimization_results = {\n",
    "    \"initial_states\": {},\n",
    "    \"final_states\": {},\n",
    "    \"training_history\": {}\n",
    "}\n",
    "\n",
    "# Initialisiere die gemeinsame Trainingsmatrix (Anfangswerte nahe Null)\n",
    "current_training_matrix = np.random.uniform(0, np.pi/8, (qubits, depth, 3))\n",
    "\n",
    "# Optimiere für jede Eingabematrix\n",
    "for i, (matrix, name) in enumerate(zip(input_matrices, matrix_names)):\n",
    "    target_state = target_states[name]\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Optimierung für {name} mit Zielzustand '{target_state}'\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Führe die Optimierung durch\n",
    "    optimized_matrix, history = optimize_for_target_state(\n",
    "        input_matrix=matrix,\n",
    "        training_matrix=current_training_matrix,\n",
    "        target_state=target_state,\n",
    "        iterations=training_iterations\n",
    "    )\n",
    "    \n",
    "    # Aktualisiere die Trainingsmatrix für die nächste Eingabematrix\n",
    "    current_training_matrix = optimized_matrix\n",
    "    \n",
    "    # Speichere die Ergebnisse\n",
    "    optimization_results[\"initial_states\"][i] = {\n",
    "        \"name\": name,\n",
    "        \"state\": target_state,\n",
    "        \"probability\": initial_measurements[i][\"target_probability\"]\n",
    "    }\n",
    "    \n",
    "    # Berechne die finale Wahrscheinlichkeit\n",
    "    final_prob = history[-1][\"target_probability\"] if history else 0.0\n",
    "    optimization_results[\"final_states\"][i] = {\n",
    "        \"name\": name,\n",
    "        \"state\": target_state,\n",
    "        \"probability\": final_prob,\n",
    "        \"loss\": history[-1][\"loss\"] if history else 1.0\n",
    "    }\n",
    "    \n",
    "    optimization_results[\"training_history\"][i] = history\n",
    "    \n",
    "    print(f\"Optimierung abgeschlossen. Finale Wahrscheinlichkeit für '{target_state}': {final_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisierung des Trainingsfortschritts\n",
    "\n",
    "Lassen Sie uns den Trainingsfortschritt für jede Matrix visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsfortschritt visualisieren\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for matrix_idx, history in optimization_results[\"training_history\"].items():\n",
    "    iterations = [entry[\"iteration\"] for entry in history]\n",
    "    probabilities = [entry[\"target_probability\"] for entry in history]\n",
    "    \n",
    "    matrix_name = optimization_results[\"initial_states\"][matrix_idx][\"name\"]\n",
    "    target_state = optimization_results[\"initial_states\"][matrix_idx][\"state\"]\n",
    "    \n",
    "    plt.plot(iterations, probabilities, marker='o', linewidth=2, \n",
    "             label=f\"{matrix_name} → '{target_state}'\")\n",
    "\n",
    "plt.title(\"Trainingsfortschritt - Wahrscheinlichkeit des Zielzustands\", fontsize=16)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Wahrscheinlichkeit\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Finale Validierung\n",
    "\n",
    "Jetzt validieren wir die optimierte Trainingsmatrix mit jeder Eingabematrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validierung mit der optimierten Trainingsmatrix\n",
    "validation_results = []\n",
    "\n",
    "for i, (matrix, name) in enumerate(zip(input_matrices, matrix_names)):\n",
    "    target_state = target_states[name]\n",
    "    \n",
    "    # Erstelle einen neuen Circuit mit der optimierten Trainingsmatrix und der aktuellen Eingabematrix\n",
    "    circuit = Circuit(qubits, depth, \n",
    "                      training_phases=current_training_matrix.tolist(),\n",
    "                      activation_phases=matrix.tolist(), \n",
    "                      shots=1024)\n",
    "    \n",
    "    # Führe den Circuit aus und erhalte die Counts\n",
    "    circuit.place_measurement()\n",
    "    circuit.run()\n",
    "    counts = circuit.get_counts()\n",
    "    \n",
    "    # Berechne die Wahrscheinlichkeiten\n",
    "    probabilities = circuit.get_state_probabilities(counts)\n",
    "    \n",
    "    # Ermittle den wahrscheinlichsten Zustand\n",
    "    sorted_states = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    most_probable_state = sorted_states[0][0] if sorted_states else \"N/A\"\n",
    "    most_probable_prob = sorted_states[0][1] if sorted_states else 0\n",
    "    target_probability = probabilities.get(target_state, 0)\n",
    "    \n",
    "    # Speichere die Ergebnisse\n",
    "    validation_results.append({\n",
    "        \"matrix_name\": name,\n",
    "        \"target_state\": target_state,\n",
    "        \"most_probable_state\": most_probable_state,\n",
    "        \"most_probable_prob\": most_probable_prob,\n",
    "        \"target_probability\": target_probability,\n",
    "        \"is_correct\": most_probable_state == target_state,\n",
    "        \"initial_probability\": initial_measurements[i][\"target_probability\"]\n",
    "    })\n",
    "\n",
    "# Vergleichstabelle: Anfangs- vs. Endwahrscheinlichkeiten\n",
    "print(\"Vergleich der Wahrscheinlichkeiten vor und nach der Optimierung:\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Matrix':10s} | {'Zielzustand':12s} | {'Anfangs-W.':10s} | {'End-W.':10s} | {'Änderung':10s} | {'Korrekt':8s}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for result in validation_results:\n",
    "    initial_prob = result[\"initial_probability\"]\n",
    "    final_prob = result[\"target_probability\"]\n",
    "    change = final_prob - initial_prob\n",
    "    change_str = f\"{change:+.4f}\"\n",
    "    \n",
    "    print(f\"{result['matrix_name']:10s} | {result['target_state']:12s} | \"\n",
    "          f\"{initial_prob:.4f} | {final_prob:.4f} | {change_str} | \"\n",
    "          f\"{('✓' if result['is_correct'] else '✗'):8s}\")\n",
    "\n",
    "print(\"-\" * 90)\n",
    "print(f\"Korrekte Klassifikationen: {sum(1 for r in validation_results if r['is_correct'])} von {len(validation_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Abschließende Visualisierung\n",
    "\n",
    "Erstellen wir eine visuelle Zusammenfassung der Optimierungsergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Verbesserung für jede Matrix\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "matrix_names = [r[\"matrix_name\"] for r in validation_results]\n",
    "initial_probs = [r[\"initial_probability\"] for r in validation_results]\n",
    "final_probs = [r[\"target_probability\"] for r in validation_results]\n",
    "\n",
    "x = np.arange(len(matrix_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, initial_probs, width, label='Vor Optimierung', color='skyblue')\n",
    "plt.bar(x + width/2, final_probs, width, label='Nach Optimierung', color='coral')\n",
    "\n",
    "plt.title(\"Verbesserung der Zielzustandswahrscheinlichkeit durch Optimierung\", fontsize=16)\n",
    "plt.xlabel(\"Eingabematrix\")\n",
    "plt.ylabel(\"Wahrscheinlichkeit\")\n",
    "plt.xticks(x, [f\"{name}\\n'{validation_results[i]['target_state']}'\" \n",
    "               for i, name in enumerate(matrix_names)])\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend()\n",
    "\n",
    "# Füge Werte über den Balken hinzu\n",
    "for i, (initial, final) in enumerate(zip(initial_probs, final_probs)):\n",
    "    plt.text(i - width/2, initial + 0.02, f\"{initial:.3f}\", ha='center')\n",
    "    plt.text(i + width/2, final + 0.02, f\"{final:.3f}\", ha='center')\n",
    "    # Verbesserung anzeigen\n",
    "    change = final - initial\n",
    "    color = 'green' if change > 0 else 'red'\n",
    "    plt.text(i, max(initial, final) + 0.1, f\"{change:+.3f}\", ha='center', \n",
    "             color=color, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap der optimierten Trainingsmatrix\n",
    "plt.figure(figsize=(12, 6))\n",
    "optimized_flat = current_training_matrix.reshape(qubits, -1)\n",
    "sns.heatmap(optimized_flat, cmap=\"viridis\", vmin=0, vmax=2*np.pi)\n",
    "plt.title(\"Optimierte Trainingsmatrix\", fontsize=16)\n",
    "plt.xlabel(\"Parameter (flach: Tiefe × 3 Phasen)\")\n",
    "plt.ylabel(\"Qubit\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Zusammenfassung und Schlussfolgerungen\n",
    "\n",
    "In diesem Tutorial haben wir gesehen, wie mit L-Gates in Quantum Circuits eine Klassifikationsaufgabe gelöst werden kann:\n",
    "\n",
    "1. **L-Gate-Struktur**: Wir haben die L-Gate-Struktur kennengelernt, die aus einer spezifischen Abfolge von Trainingsphasen (TP), Inputphasen (IP) und Hadamard-Gates (H) besteht.\n",
    "\n",
    "2. **Eingabematrizen**: Wir haben verschiedene Eingabematrizen erstellt und jeder einen eindeutigen Zielzustand zugewiesen.\n",
    "\n",
    "3. **Optimierung**: Mit dem Adam-Optimierer haben wir die Trainingsparameter optimiert, damit der Circuit bei verschiedenen Eingaben die zugehörigen Zielzustände mit höherer Wahrscheinlichkeit liefert.\n",
    "\n",
    "4. **Evaluation**: Wir haben den Erfolg der Optimierung gemessen, indem wir die Wahrscheinlichkeiten der Zielzustände vor und nach dem Training verglichen haben.\n",
    "\n",
    "Diese Methode demonstriert, wie Quantum Circuits als Klassifikatoren eingesetzt werden können und wie durch gezielte Optimierung der Trainingsparameter die gewünschten Zuordnungen erreicht werden.\n",
    "\n",
    "In realen Anwendungen könnte dieser Ansatz für Mustererkennung, Datenklassifikation oder sogar für maschinelles Lernen auf Quantencomputern genutzt werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}